# -*- coding: utf-8 -*-
"""Assignment1 366(4).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19lyPWX0Qt6TqyRD-NLz7Sq08VS_SoPbN
"""

#Step 1:
import random

class Environment:
    def __init__(self):
        self.grid_size = 10
        self.grid = [[0] * self.grid_size for _ in range(self.grid_size)]
        self.start_position = 0
        self.end_position = 0
        self.obstacles = []

    def generate_obstacles(self, num_obstacles):
        for _ in range(num_obstacles):
            obstacle_x = random.randint(0, self.grid_size - 1)
            obstacle_y = random.randint(0, self.grid_size - 1)
            self.obstacles.append((obstacle_x, obstacle_y))
            self.grid[obstacle_x][obstacle_y] = 1

    def generate_start_and_end_positions(self):
        start_x, start_y = (0,0)
        end_x, end_y = (8,9)

        while (start_x, start_y) in self.obstacles:
            start_x, start_y = (0,0)

        while (end_x, end_y) in self.obstacles or (end_x, end_y) == (start_x, start_y):
            end_x, end_y = (8,9)

        self.start_position = (start_x, start_y)
        self.end_position = (end_x, end_y)

    def display_grid(self):
        for i in range(self.grid_size):
            for j in range(self.grid_size):
                if (i, j) == self.start_position:
                    print("S", end=" ")
                elif (i, j) == self.end_position:
                    print("E", end=" ")
                elif (i, j) in self.obstacles:
                    print("X", end=" ")
                else:
                    print(".", end=" ")
            print()

env = Environment()
env.generate_obstacles(15)
env.generate_start_and_end_positions()
env.display_grid()

#Step 2:
class Agent:
    def __init__(self, start_position=(0, 0), energy_level=100):
        self.current_position = start_position
        self.energy_level = energy_level
        self.battery_status = 100

    def move(self, new_position):
        # Calculate the energy cost for the move
        energy_cost = 10
        # if there is enough battery level to move
        if self.battery_status >= energy_cost:
            self.current_position = new_position
            self.battery_status -= energy_cost
            print(f"Moved to position {new_position}. Battery level: {self.battery_status}%")
            return True
        else:
            print("Battery level too low. Recharging...")
            self.recharge_battery()
            return False

    def recharge_battery(self):
        # Recharge the battery to 100%
        self.battery_status = 100
        print("Battery recharged to 100%.")


agent = Agent()
print(f"Initial position: {agent.current_position}")

# Moving to a new position
new_position = (1, 1)
agent.move(new_position)

# Moving again
agent.move((2, 2))

# Recharge the battery
agent.recharge_battery()

# Try again after recharging
agent.move((2, 2))

#Step 3:
import random
import time

class Environment:
    def __init__(self):
        self.grid_size = 10
        self.grid = [[0] * self.grid_size for _ in range(self.grid_size)]
        self.start_position = None
        self.end_position = None
        self.obstacles = []

    def generate_obstacles(self, num_obstacles):
        for _ in range(num_obstacles):
            obstacle_x = random.randint(0, self.grid_size - 1)
            obstacle_y = random.randint(0, self.grid_size - 1)
            self.obstacles.append((obstacle_x, obstacle_y))
            self.grid[obstacle_x][obstacle_y] = 1

    def generate_start_and_end_positions(self):
        start_x, start_y = (0,0)
        end_x, end_y = (8,9)

        while (start_x, start_y) in self.obstacles:
            start_x, start_y = (0,0)

        while (end_x, end_y) in self.obstacles or (end_x, end_y) == (start_x, start_y):
            end_x, end_y = (8,9)

        self.start_position = (start_x, start_y)
        self.end_position = (end_x, end_y)

    def display_grid(self, agent_position):
        for i in range(self.grid_size):
            for j in range(self.grid_size):
                if (i, j) == self.start_position:
                    print("S", end=" ")
                elif (i, j) == self.end_position:
                    print("E", end=" ")
                elif (i, j) in self.obstacles:
                    print("X", end=" ")
                elif (i, j) == agent_position:
                    print("R", end=" ")
                else:
                    print(".", end=" ")
            print()
        print()

class Agent:
    def __init__(self, start_position=(0, 0), energy_level=100):
        self.current_position = start_position
        self.energy_level = energy_level
        self.battery_status = 100

    def move(self, new_position):

        energy_cost = 10

        if self.battery_status >= energy_cost:
            self.current_position = new_position
            self.battery_status -= energy_cost
            print(f"Moved to position {new_position}. Battery level: {self.battery_status}%")
            return True
        else:
            print("Battery level too low. Recharging...")
            self.recharge_battery()
            return False

    def recharge_battery(self):

        self.battery_status = 100
        print("Battery recharged to 100%.")

def simulate_movement(env, agent):
    while agent.current_position != env.end_position:

        env.display_grid(agent.current_position)


        possible_moves = [(0, 1), (0, -1), (1, 0), (-1, 0)]
        random_move = random.choice(possible_moves)
        new_position = (agent.current_position[0] + random_move[0], agent.current_position[1] + random_move[1])


        if 0 <= new_position[0] < env.grid_size and 0 <= new_position[1] < env.grid_size and new_position not in env.obstacles:
            agent.move(new_position)
        else:
            print("Invalid move. Trying again...")


        time.sleep(1)

    print("Destination reached!")

env = Environment()
env.generate_obstacles(15)
env.generate_start_and_end_positions()
agent = Agent(start_position=env.start_position)
simulate_movement(env, agent)

#Step 4-1:
import heapq

def euclidean_distance(point1, point2):
    return ((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2) ** 0.5

def uniform_cost_search(env, start, goal):
    frontier = [(0, start)]
    came_from = {}
    cost_so_far = {start: 0}

    while frontier:
        current_cost, current_position = heapq.heappop(frontier)

        if current_position == goal:
            break

        for next_position in get_neighbors(env, current_position):
            new_cost = cost_so_far[current_position] + 1
            if next_position not in cost_so_far or new_cost < cost_so_far[next_position]:
                cost_so_far[next_position] = new_cost
                heapq.heappush(frontier, (new_cost, next_position))
                came_from[next_position] = current_position

    path = reconstruct_path(start, goal, came_from)
    return path

def a_star(env, start, goal):
    frontier = [(0, start)]
    came_from = {}
    cost_so_far = {start: 0}

    while frontier:
        current_cost, current_position = heapq.heappop(frontier)

        if current_position == goal:
            break

        for next_position in get_neighbors(env, current_position):
            new_cost = cost_so_far[current_position] + 1
            if next_position not in cost_so_far or new_cost < cost_so_far[next_position]:
                cost_so_far[next_position] = new_cost
                priority = new_cost + euclidean_distance(goal, next_position)
                heapq.heappush(frontier, (priority, next_position))
                came_from[next_position] = current_position

    path = reconstruct_path(start, goal, came_from)
    return path

def get_neighbors(env, position):
    neighbors = []
    for move in [(0, 1), (0, -1), (1, 0), (-1, 0)]:
        new_position = (position[0] + move[0], position[1] + move[1])
        if 0 <= new_position[0] < env.grid_size and 0 <= new_position[1] < env.grid_size and new_position not in env.obstacles:
            neighbors.append(new_position)
    return neighbors

def reconstruct_path(start, goal, came_from):
    current_position = goal
    path = []
    while current_position != start:
        path.append(current_position)
        current_position = came_from[current_position]
    path.append(start)
    path.reverse()
    return path

#Step 4-2:
def evaluate_algorithm(env, start, goal, algorithm):
    agent = Agent(start_position=start)
    path = algorithm(env, start, goal)
    num_recharges = 0

    for i in range(len(path) - 1):
        if not agent.move(path[i]):
            num_recharges += 1
            agent.recharge_battery()
            agent.move(path[i])

    agent.move(goal)

    return num_recharges


env = Environment()
env.generate_obstacles(15)  # Generate 15 obstacles
env.generate_start_and_end_positions()  # Generate start and end positions

start = env.start_position
goal = env.end_position

num_recharges_ucs = evaluate_algorithm(env, start, goal, uniform_cost_search)
num_recharges_astar = evaluate_algorithm(env, start, goal, a_star)

print("Number of recharges for UCS:", num_recharges_ucs)
print("Number of recharges for A*:", num_recharges_astar)

#Step 5-1:
import numpy as np
import matplotlib.pyplot as plt

class Agent:
    def __init__(self, start_position=(0, 0), energy_level=100):
        self.current_position = start_position
        self.energy_level = energy_level
        self.battery_status = [100]
        self.positions = [start_position]

    def move(self, new_position):

        energy_cost = 10
        if self.battery_status[-1] >= energy_cost:
            self.current_position = new_position
            self.battery_status.append(self.battery_status[-1] - energy_cost)
            self.positions.append(new_position)
            print(f"Moved to position {new_position}. Battery level: {self.battery_status[-1]}%")
            return True
        else:
            print("Battery level too low. Recharging...")
            self.recharge_battery()
            return False

    def recharge_battery(self):

        self.battery_status.append(100)
        print("Battery recharged to 100%.")

#Step 5-2:
def visualize_simulation(env, agent):
    fig, ax = plt.subplots()


    for i in range(env.grid_size):
        for j in range(env.grid_size):
            if (i, j) in env.obstacles:
                ax.add_patch(plt.Rectangle((i, j), 1, 1, color='gray'))
            else:
                ax.add_patch(plt.Rectangle((i, j), 1, 1, color='lightgray'))
    ax.set_xlim(0, env.grid_size)
    ax.set_ylim(0, env.grid_size)


    ax.plot(env.start_position[0] + 0.5, env.start_position[1] + 0.5, 'bo', markersize=10, label='Start')
    ax.plot(env.end_position[0] + 0.5, env.end_position[1] + 0.5, 'ro', markersize=10, label='End')


    positions = np.array(agent.positions)
    ax.plot(positions[:, 0] + 0.5, positions[:, 1] + 0.5, 'g-', linewidth=2, label='Robot Path')


    ax2 = ax.twinx()
    ax2.plot(range(len(agent.battery_status)), agent.battery_status, 'b-', label='Battery Level')

    ax.legend(loc='upper left')
    ax2.legend(loc='upper right')
    ax.set_aspect('equal', 'box')
    ax.grid(True)

    plt.title('Robot Navigation Simulation')
    plt.xlabel('X')
    plt.ylabel('Y')
    ax2.set_ylabel('Battery Level (%)')
    plt.show()


env = Environment()
env.generate_obstacles(15)
env.generate_start_and_end_positions()
agent = Agent(start_position=env.start_position)
simulate_movement(env, agent)
visualize_simulation(env, agent)

#Step 6-1:
class Agent:
    def __init__(self, start_position=(0, 0), energy_level=100):
        self.current_position = start_position
        self.energy_level = energy_level
        self.battery_status = [100]
        self.positions = [start_position]

    def move(self, new_position):

        energy_cost = 10

        if self.battery_status[-1] >= energy_cost:
            self.current_position = new_position
            self.battery_status.append(self.battery_status[-1] - energy_cost)
            self.positions.append(new_position)
            print(f"Moved to position {new_position}. Battery level: {self.battery_status[-1]}%")
            return True
        else:
            print("Battery level too low. Recharging...")
            self.recharge_battery()
            return False

    def recharge_battery(self):

        self.battery_status.append(100)
        print("Battery recharged to 100%.")

    def optimize_path(self, env, goal):
        path = a_star(env, self.current_position, goal)
        return path

    def detect_collision(self, new_position, env):
        if new_position in env.obstacles or not (0 <= new_position[0] < env.grid_size and 0 <= new_position[1] < env.grid_size):
            return True
        else:
            return False

    def avoid_collision(self, env, goal):
        possible_moves = [(0, 1), (0, -1), (1, 0), (-1, 0)]
        for move in possible_moves:
            new_position = (self.current_position[0] + move[0], self.current_position[1] + move[1])
            if not self.detect_collision(new_position, env):
                return new_position
        return self.current_position

#Step 6-2:
def simulate_movement(env, agent):
    goal = env.end_position
    while agent.current_position != goal:
        env.display_grid(agent.current_position)

        path = agent.optimize_path(env, goal)

        for next_position in path:
            if agent.detect_collision(next_position, env):
                print("Collision detected. Avoiding collision...")
                new_position = agent.avoid_collision(env, goal)
                agent.move(new_position)
            else:
                agent.move(next_position)
                break

        time.sleep(1)

    print("Destination reached!")